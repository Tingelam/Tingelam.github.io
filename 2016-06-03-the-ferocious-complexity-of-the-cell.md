Ray Kurzweil AI Salon:

Agree with Ray that we need to understand the brain to build superhuman intelligence. But, it will be much harder than simple forecasts indicate.
Argument for complexity. 50 years ago first molecular dynamics papers simulated systems with 10s of atoms for picoseconds (10^-12).
Today, due to tremendous gains in Moore’s law, we can simulate systems with 100,000s of atoms for milliseconds (10^-3). 10^4 increase in size, 10^9 increase in time, for a total of 13 orders of magnitude.
But how complex is an actual cell? Estimates vary, but perhaps one trillion (10^12) atoms in a small cell. Cellular processes take much longer. Cell division on the order of hours. Let’s say 8 hrs for a standard cell. Exhaustively understanding a single cell would consequently take 10 million fold (7 orders) of spatial improvement and about 10 million fold (10^7) increase in time complexity. Total of 14 orders of magnitude.
But then, what about understanding a human brain? There are 100-billion neurons in the brain, and human-learning occurs on the order of years (say 1 year). To understand the brain requires  100-billion (10^11) fold increase in spatial complexity, and 1000-fold (10^3) increase in time complexity. Another 14 orders of magnitude.
Thus assuming Moore’s law keeps humming along at its exponential rate (by no means guaranteed!), it will take us 100 years to understand the brain…
But wait, won’t there be a feedback effect from our deeper understanding of algorithms? Yes, but there will be a counter feedback: QM is much more intricately linked to biological function than is apparent. We can’t even model ATP in our complex simulations. Counter exponential feedback.

