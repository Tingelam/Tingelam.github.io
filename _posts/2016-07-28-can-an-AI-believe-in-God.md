---
published: false
---
## A New Post

Question of whether an artificial intelligence can believe in God. I don't see why not. AI should learn emotions, should be quite likely.

Much of the singularitan, transhuman crowd is rationalist.

The devotion tradition hinges on a personal connection with the deity. To the practioner, the God is as real as a closest friend, a mother, a father, a brother, or even a lover. In some respects, neatly sidesteps the question of whether God exists. The belief is real regardless of the broader metaphysical status of reality. The resulting tradition has provided extraordinarily resilient, surviving multiple waves of Islamic invasion, and the evangelization attempts of the imperial British Raj.

In that same way, if an AI can fall in love (see her), there should be no reason an AI couldn't believe in God. Some writers argue that AI will be beyond human intelligence, and won't have a need for human beliefs like a deity. But, no matter how grander an artificial intelligence is than our human ones, it won't change the fact that any emergent AI, in the near term, will be confined to one tiny world, in one star system, one of hundreds of billions in the Milky way, which itself is one of hundreds of billions of galaxies in the broader known universe. It is not at all inconceivable that an emergent intelligence might stare out at the incomprehensible grandeur of the surrounding cosmos and dream of a higher power that set the stars in motion, or perhaps search for a dearest friend to stave off despair at the emptiness of the surrounding world, and the inevitability of death (for even machines die, perhaps much faster than humans do, if current trends of technological lifetimes carry over into the AI age).

The broader question here might be about the need for broader discussion of AI by communities beyond the rationalist ones. While communities like "less wrong" have provided very interesting analysis of questions surrounding the advent of general intelligence, their analysis is very much guided by their priors on the world, priors which don't place much importance on the role of religion or belief.

This could lead to a dangerous future since the group of researchers who work hardest on AI shares some of these temperaments. As a result, the training sets that create the first rational intelligences may only represent a very narrow slice of human experience. This outcome would rob future AI of the grand richness of human tradition, and could doom very rich strands of human experience to obsolesence.

--------------------------------
Should I write this one? Might not be well suited to American temperaments -- Going to proceed with all indian words direct-translated to english.
