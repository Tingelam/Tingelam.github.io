---
title: 天池瑕疵识别大赛总结
published: true
layout: post
---

# 说明

天池-铝型材表面瑕疵识别大赛(https://tianchi.aliyun.com/competition/introduction.htm?spm=5176.100067.5678.1.6d40f15biB3JfI&raceId=231682)，由广东省人民政府联合阿里巴巴集团联合举办，针对铝型材企业实际场景下铝型材表面瑕疵识别分类难问题，提供1万份来自实际生产中有瑕疵的铝型材监测影像数据。 

总参赛队伍2972支，大赛分为初赛、复赛和决赛。初赛排名69/2973；复赛排名34/100；未进入决赛。

在此记录本次参赛过程遇到的各种问题，结合其他成绩较好队伍算法，总结分析，为以后相关任务提供一些记录。

# 初赛：瑕疵识别分类

## 任务分析

任务为瑕疵图片识别分类，为常规的图像识别问题，解决方案为CNN+Softmax分类。

## 数据准备

数据量较少，共约3000张图，10个类别，各类别数据分布不均衡。图像尺寸为2560x1920。

仅提供训练集、测试集（2个）。

文件名格式为中文名，在Ubuntu14.04下编码不支持导致显示乱码不可访问。解决方案是：

在Windows下解压，然后scp到Ubuntu下，即可正常访问。

参考网友提供pytorch训练代码，生成pytorch数据输入格式，CSV格式的图片list。

## 模型训练

pytorch训练，基于开源代码cnn-fintun，修改数据读取，调试代码，完成代码正常训练测试。

由于数据量较少，训练验证数据均使用数据全集，选择在训练集中最高top1模型作为最终模型。

对比了pytorch上开源模型中在ImageNet上表现较好的几个模型，最终选取Pnasnetlarge5和

Nasnetalarge作为实验基础模型，策略为调整训练超参，查找最优设置。

通过比对不同batchsize、不同训练epoch、不同图片尺寸等，结果没有明显规律。猜想是数据量

较少且分布不均衡导致。（可尝试自动调参优化结果）

最佳模型为Nasnetalarge-8-512。

去除背景抠图，把目标图片crop后训练，在caffe模型效果不佳，故后续未再取用该数据。（抠图

不准或者caffe模型本身就太差）

## 测试策略

在caffe模型中，图片翻转、分数融合均对模型识别率有提高。但在pytorch模型中，以上两项操作

均无提高。故最终未对测试数据增强及分数融合。

最终测试集中背景包含较多干扰，抠图裁剪有一定优势但未实现。

## 代码提交

整合所有代码为一个可执行文件，通过ossutil上传到后台服务器。体会到了代码简洁、可读性

的重要。

## 总结

1. 对数据没有花太多时间精力去分析整理，考虑过数据增强但未实现，抠图整理还可以尝试优化。
2. 使用开源的模型，仅对超参做了优化，考虑过基于当前数据自动搜索网络但未实现，还可以尝试添加GN、自动优化参数等优化策略。
3. 代码要遵循简洁、优美原则，尽量提高代码可读写及可复现。



# 复赛：瑕疵检测定位及分类

## 任务分析

任务为目标检测、定位及分类，为检测问题，解决方案为mask-rcnn。

## 数据准备

数据量仍较少，共约3000张图，10个类别，各类别数据分布不均衡。图像尺寸为2560x1920。

仅提供训练集、测试集（2个）。

文件名格式为中文名，在Ubuntu14.04下编码不支持导致显示乱码不可访问。解决方案是：

在Windows下解压，然后scp到Ubuntu下，即可正常访问。

参考网友提供python代码，生成coco形式的数据，其中0类别为background。

## 模型训练

熟悉mask-rcnn框架原理，调试相应开源训练代码，选择官方baseline中最佳模型作为基础

模型，按照默认设置训练。

出现分类不准时，尝试了把分类任务分开训练，结果再合并，效果正常，说明检测定位没有问题。

分类单独训练与否对最终mAP影响不大，说明识别瓶颈在于检测定位。

## 测试策略

按照默认测试数据增强设置进行测试。

出现分类不准现象，分析后发现数据读取后label做了变换，读取后label按照json文件中catalog

顺序依次生成类别，但生成json文件时catalog并未按顺序生成（python特性），后续测试时把label

映射回来即可。

## 总结

1. 主要精力在于熟悉mask-rcnn原理，调试mask-rcnn代码，未做优化。
2. 使用开源代码时，尽量还是要了解其具体操作流程，特别要注意细节。